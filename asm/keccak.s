0000000000000438 <KeccakF1600_StatePermute>:
     push   %rbx
     push   %rbp
     push   %r12
     push   %r13
     push   %r14
     push   %r15
     sub    $0xc8,%rsp
     mov    (%rdi),%rsi
     mov    0x8(%rdi),%rbp
     mov    0x20(%rdi),%r15
     xor    0x28(%rdi),%rsi
     xor    0x30(%rdi),%rbp
     xor    0x48(%rdi),%r15
     xor    0x50(%rdi),%rsi
     xor    0x58(%rdi),%rbp
     xor    0x70(%rdi),%r15
     xor    0x78(%rdi),%rsi
     xor    0x80(%rdi),%rbp
     xor    0x98(%rdi),%r15
     xor    0xa0(%rdi),%rsi
     xor    0xa8(%rdi),%rbp
     mov    0xb0(%rdi),%rdx
     mov    0xb8(%rdi),%r8
     xor    0xc0(%rdi),%r15

     mov    %rbp,%rbx

     shld   $0x1,%rbx,%rbx
     mov    0x10(%rdi),%r12
     xor    0x38(%rdi),%rdx
     xor    0x60(%rdi),%r12
     xor    %r15,%rbx
     xor    0x88(%rdi),%rdx
     xor    %rdx,%r12
     mov    %r12,%rcx
     shld   $0x1,%rcx,%rcx
     mov    0x18(%rdi),%r13
     xor    0x40(%rdi),%r8
     xor    0x68(%rdi),%r13
     xor    %rsi,%rcx
     xor    0x90(%rdi),%r8
     xor    %r8,%r13
     mov    %r13,%rdx
     shld   $0x1,%rdx,%rdx
     mov    %r15,%r8
     xor    %rbp,%rdx
     shld   $0x1,%r8,%r8
     mov    %rsi,%r9
     xor    %r12,%r8
     shld   $0x1,%r9,%r9
     mov    (%rdi),%r10
     mov    0x30(%rdi),%r11
     xor    %r13,%r9
     mov    0x60(%rdi),%r12
     mov    0x90(%rdi),%r13
     mov    0xc0(%rdi),%r14
     xor    %rcx,%r11
     shld   $0x2c,%r11,%r11
     xor    %rdx,%r12
     xor    %rbx,%r10
     shld   $0x2b,%r12,%r12
     mov    %r11,%rsi
     movabs $0xcc00000000000001,%rax
     
     or     %r12,%rsi
     xor    %r10,%rax
     xor    %rax,%rsi
     mov    %rsi,(%rsp)
     xor    %r9,%r14
     shld   $0xe,%r14,%r14
     mov    %r10,%r15
     and    %r11,%r15
     xor    %r14,%r15
     mov    %r15,0x20(%rsp)
     xor    %r8,%r13
     shld   $0x15,%r13,%r13
     mov    %r13,%rax
     and    %r14,%rax
     xor    %r12,%rax
     mov    %rax,0x10(%rsp)
     not    %r12
     or     %r10,%r14
     or     %r13,%r12
     xor    %r13,%r14
     xor    %r11,%r12
     mov    %r14,0x18(%rsp)
     mov    %r12,0x8(%rsp)
     mov    %r12,%rbp
     mov    0x48(%rdi),%r11
     xor    %r9,%r11
     mov    0x50(%rdi),%r12
     shld   $0x14,%r11,%r11
     xor    %rbx,%r12
     shld   $0x3,%r12,%r12
     mov    0x18(%rdi),%r10
     mov    %r11,%rax
     or     %r12,%rax
     xor    %r8,%r10
     mov    0x80(%rdi),%r13
     mov    0xb0(%rdi),%r14
     shld   $0x1c,%r10,%r10
     xor    %r10,%rax
     mov    %rax,0x28(%rsp)
     xor    %rax,%rsi
     xor    %rcx,%r13
     shld   $0x2d,%r13,%r13
     mov    %r12,%rax
     and    %r13,%rax
     xor    %r11,%rax
     mov    %rax,0x30(%rsp)
     xor    %rax,%rbp
     xor    %rdx,%r14
     shld   $0x3d,%r14,%r14
     mov    %r14,%rax
     or     %r10,%rax
     xor    %r13,%rax
     mov    %rax,0x40(%rsp)
     and    %r11,%r10
     xor    %r14,%r10
     mov    %r10,0x48(%rsp)
     not    %r14
     xor    %r10,%r15
     or     %r14,%r13
     xor    %r12,%r13
     mov    %r13,0x38(%rsp)
     mov    0x8(%rdi),%r10
     mov    0x38(%rdi),%r11
     mov    0x68(%rdi),%r12
     mov    0x98(%rdi),%r13
     mov    0xa0(%rdi),%r14
     xor    %rdx,%r11
     shld   $0x6,%r11,%r11
     xor    %r8,%r12
     shld   $0x19,%r12,%r12
     mov    %r11,%rax
     or     %r12,%rax
     xor    %rcx,%r10
     shld   $0x1,%r10,%r10
     xor    %r10,%rax
     mov    %rax,0x50(%rsp)
     xor    %rax,%rsi
     xor    %r9,%r13
     shld   $0x8,%r13,%r13
     mov    %r12,%rax
     and    %r13,%rax
     xor    %r11,%rax
     mov    %rax,0x58(%rsp)
     xor    %rax,%rbp
     xor    %rbx,%r14
     shld   $0x12,%r14,%r14
     not    %r13
     mov    %r13,%rax
     and    %r14,%rax
     xor    %r12,%rax
     mov    %rax,0x60(%rsp)
     mov    %r14,%rax
     or     %r10,%rax
     xor    %r13,%rax
     mov    %rax,0x68(%rsp)
     and    %r11,%r10
     xor    %r14,%r10
     mov    %r10,0x70(%rsp)
     xor    %r10,%r15
     mov    0x28(%rdi),%r11
     xor    %rbx,%r11
     mov    0x58(%rdi),%r12
     shld   $0x24,%r11,%r11
     xor    %rcx,%r12
     mov    0x20(%rdi),%r10
     shld   $0xa,%r12,%r12
     mov    %r11,%rax
     mov    0x88(%rdi),%r13
     and    %r12,%rax
     xor    %r9,%r10
     mov    0xb8(%rdi),%r14
     shld   $0x1b,%r10,%r10
     xor    %r10,%rax
     mov    %rax,0x78(%rsp)
     xor    %rax,%rsi
     xor    %rdx,%r13
     shld   $0xf,%r13,%r13
     mov    %r12,%rax
     or     %r13,%rax
     xor    %r11,%rax
     mov    %rax,0x80(%rsp)
     
     xor    %rax,%rbp
     xor    %r8,%r14
     shld   $0x38,%r14,%r14
     not    %r13
     mov    %r13,%rax
     or     %r14,%rax
     xor    %r12,%rax
     mov    %rax,0x88(%rsp)
     
     or     %r10,%r11
     xor    %r14,%r11
     mov    %r11,0x98(%rsp)
     
     and    %r10,%r14
     xor    %r13,%r14
     mov    %r14,0x90(%rsp)
     
     xor    %r11,%r15
     mov    0x10(%rdi),%r10
     mov    0x40(%rdi),%r11
     mov    0x70(%rdi),%r12
     xor    %rdx,%r10
     mov    0x78(%rdi),%r13
     shld   $0x3e,%r10,%r10
     xor    %r8,%r11
     mov    0xa8(%rdi),%r14
     shld   $0x37,%r11,%r11
     xor    %r9,%r12
     mov    %r10,%r9
     xor    %rcx,%r14
     shld   $0x2,%r14,%r14
     and    %r11,%r9
     xor    %r14,%r9
     mov    %r9,0xc0(%rsp)
     
     shld   $0x27,%r12,%r12
     xor    %r9,%r15
     not    %r11
     xor    %rbx,%r13
     mov    %r11,%rbx
     and    %r12,%rbx
     xor    %r10,%rbx
     mov    %rbx,0xa0(%rsp)
     
     xor    %rbx,%rsi
     shld   $0x29,%r13,%r13
     mov    %r12,%rcx
     or     %r13,%rcx
     xor    %r11,%rcx
     mov    %rcx,0xa8(%rsp)
     
     xor    %rcx,%rbp
     mov    %r13,%rdx
     mov    %r14,%r8
     and    %r14,%rdx
     or     %r10,%r8
     xor    %r12,%rdx
     xor    %r13,%r8
     mov    %rdx,0xb0(%rsp)
     mov    %r8,0xb8(%rsp)
     
     

     ; prologue
     add    $0xc8,%rsp
     pop    %r15
     pop    %r14
     pop    %r13
     pop    %r12
     pop    %rbp
     pop    %rbx
     retq   
